{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer, GenerationConfig\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device= \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-large')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=r\"F:\\linkedin\\job_data.csv\")\n",
    "dataset = dataset.remove_columns(column_names=['Unnamed: 0.1','Unnamed: 0'])\n",
    "dataset = dataset['train'].train_test_split(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Description', 'Company Name'],\n",
       "        num_rows: 4517\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Description', 'Company Name'],\n",
       "        num_rows: 502\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing_data(data):\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        data['Description'],\n",
    "        max_length=812,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    outputs = tokenizer(\n",
    "        data['Company Name'],\n",
    "        max_length=15,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    inputs['labels'] = outputs['input_ids']\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db7593269774bcba33d933c3221e51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4517 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 4517\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdba4a0588a4c149baf031da685b507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/502 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 502\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "training_data = dataset['train'].map(tokenizing_data,batched=True,batch_size=1)\n",
    "training_data = training_data.remove_columns(column_names=['Description','Company Name'])\n",
    "print(training_data)\n",
    "\n",
    "testing_data = dataset['test'].map(tokenizing_data,batched=True,batch_size=1)\n",
    "testing_data = testing_data.remove_columns(column_names=['Description','Company Name'])\n",
    "print(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 737668096\n",
      "all model parameters: 737668096\n",
      "percentage of trainable model parameters: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 589824\n",
      "all model parameters: 738257920\n",
      "percentage of trainable model parameters: 0.08%\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    r=2,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "peft_model_train = get_peft_model(model, lora_config)\n",
    "print(print_number_of_trainable_model_parameters(peft_model_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1376: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./output_folder\"\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=10,\n",
    "    no_cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ce4eb6d6e0454db6ef487facd8bf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./output_folder\\checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.026, 'grad_norm': 19.421674728393555, 'learning_rate': 0.000911504424778761, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./output_folder\\checkpoint-1000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5902, 'grad_norm': 4.374779224395752, 'learning_rate': 0.0008230088495575221, 'epoch': 1.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./output_folder\\checkpoint-1500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5562, 'grad_norm': 43.0243034362793, 'learning_rate': 0.0007345132743362832, 'epoch': 2.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./output_folder\\checkpoint-2000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5365, 'grad_norm': 5.459060192108154, 'learning_rate': 0.0006460176991150443, 'epoch': 3.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Checkpoint destination directory ./output_folder\\checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4738, 'grad_norm': 4.174365043640137, 'learning_rate': 0.0005575221238938053, 'epoch': 4.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4752, 'grad_norm': 8.707856178283691, 'learning_rate': 0.0004690265486725664, 'epoch': 5.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4306, 'grad_norm': 5.454799652099609, 'learning_rate': 0.00038053097345132743, 'epoch': 6.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4148, 'grad_norm': 4.428890228271484, 'learning_rate': 0.0002920353982300885, 'epoch': 7.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3887, 'grad_norm': 8.56505012512207, 'learning_rate': 0.00020353982300884958, 'epoch': 7.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.365, 'grad_norm': 1.1471303701400757, 'learning_rate': 0.00011504424778761063, 'epoch': 8.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3475, 'grad_norm': 2.023759126663208, 'learning_rate': 2.6548672566371683e-05, 'epoch': 9.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 248044.1537, 'train_samples_per_second': 0.182, 'train_steps_per_second': 0.023, 'train_loss': 0.5053076077351528, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5650, training_loss=0.5053076077351528, metrics={'train_runtime': 248044.1537, 'train_samples_per_second': 0.182, 'train_steps_per_second': 0.023, 'train_loss': 0.5053076077351528, 'epoch': 10.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer = Trainer(\n",
    "    model=peft_model_train, \n",
    "    args=peft_training_args,\n",
    "    train_dataset = training_data,\n",
    "    eval_dataset=testing_data,\n",
    "    )\n",
    "\n",
    "peft_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./output_t5_model\\\\tokenizer_config.json',\n",
       " './output_t5_model\\\\special_tokens_map.json',\n",
       " './output_t5_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.model.save_pretrained(\"./output_t5_model\")\n",
    "tokenizer.save_pretrained(\"./output_t5_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"t5-large\")\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base, \"./output_t5_model\", is_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_inputs = tokenizer.encode(\"job title aiml engineerlocation 100% remote quarterly travel company hqcompensation based experience qualifications subject base salary bonusabout east 57th street partners internationaleast 57th street partners international partners companies forefront technology provide innovative solutions ai machine learning executive direct hire search practice place technical leaders drive cuttingedge development optimizationposition overviewour client seeking aiml engineer join remote team lead development machine learning models enhance product offerings aiml engineer work closely data scientists software developers build train deploy models solve realworld problems position requires quarterly travel companyâ€™s headquarters key strategic discussions collaborationkey responsibilitiesdesign develop implement ai machine learning algorithmscollaborate crossfunctional teams integrate ai solutions existing productsuse advanced statistical techniques identify patterns build predictive modelstrain machine learning models optimize performance monitor outcomesstay updated latest advancements aiml technologies implement best practiceswork large datasets develop scalable ai solutionsqualificationsbachelorâ€™s masterâ€™s degree computer science ai machine learning related fieldproven experience aiml development including model building deploymentproficiency python tensorflow pytorch aiml frameworksstrong problemsolving analytical skillsability work independently remote setting collaborating global teamscompensation benefitscompetitive compensation package based experience qualifications including base salary bonusaccess cuttingedge aiml projects professional development opportunities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accenture in India'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer(dataset['train']['Description'][2004], return_tensors=\"pt\").input_ids\n",
    "peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project role ai ml engineer project role description develops applications systems utilize ai tools cloud ai services proper cloud onprem application pipeline production ready quality able apply genai models part solution could also include limited deep learning neural networks chatbots image processing must skills google cloud machine learning services maestro good skills na minimum 5 years experience required educational qualification 15 years full time education summary aiml engineer develop applications systems utilize ai tools cloud ai services responsible creating proper cloud onprem application pipeline productionready quality additionally apply genai models part solution may include deep learning neural networks chatbots image processing roles & responsibilities expected sme collaborate manage team perform responsible team decisions engage multiple teams contribute key decisions provide solutions problems immediate team across multiple teams develop applications systems utilizing ai tools cloud ai services create proper cloud onprem application pipeline productionready quality apply genai models part solution utilize deep learning neural networks chatbots image processing enhance applications professional & technical skills must skills proficiency google cloud machine learning services strong understanding statistical analysis machine learning algorithms experience data visualization tools tableau power bi handson implementing various machine learning algorithms linear regression logistic regression decision trees clustering algorithms solid grasp data munging techniques including data cleaning transformation normalization ensure data quality integrity additional information candidate minimum 5 years experience google cloud machine learning services position based bengaluru office 15 years fulltime education required 15 years full time education'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['Description'][2004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accenture in India'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['Company Name'][2004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(\"\"\"We are looking for an experienced developer to join our team. You must have 1 to 3 years of work experience in ML/AI - Computer Vision and should have delivered at least 2 Deep Learning projects.\n",
    "\n",
    "Who am I?\n",
    "\n",
    "Have delivered at least 2 Deep Learning projects.\n",
    "A self-learner and result-oriented individual with an ability to work in teams and help scale the teams.\n",
    "Have a delivery and client-oriented approach.\n",
    "Have good written and verbal communication skills.\n",
    "Have a problem-solving approach and can work independently.\n",
    "Have deep knowledge of math, probability, statistics and algorithms.\n",
    "Passion for continuing to learn state-of-the-art techniques in ML/Data science.\n",
    "Any Science or Engineering graduate\n",
    "What should my technical skills be?\n",
    "\n",
    "Have proficient knowledge of deep learning frameworks such as PyTorch, TensorFlow or Keras.\n",
    "Hands-on experience with Python and libraries like OpenCV and Pillow.\n",
    "Familiarity with object detection algorithms like FasterRCNN, Yolo, SSD.\n",
    "Knowledge of frameworks like Detectron2\n",
    "Working knowledge of how Neural Network works and various pre-trained models.\n",
    "Knowledge of models like XGBOOST.\n",
    "Experience in Model Conversion (ONNX).\n",
    "Expertise in visualizing and manipulating big datasets.\n",
    "Understanding of data structures, data modelling and software architecture.\n",
    "Experience in working on C++ is an added advantage\n",
    "What will I do?\n",
    "\n",
    "Research machine learning algorithms and implement by tailoring to particular business needs.\n",
    "Work on training and identifying Products and Objects using Computer Vision.\n",
    "Provide analytical support to improve quality and standard work results.\n",
    "Deploy solutions involving Image processing.\n",
    "Pipeline deployment of Models and their ensembling.\n",
    "Why should I join Big Rattle?\n",
    "\n",
    "Big Rattle Technologies specializes into development of Mobile and Web applications. Our clients include Fortune 5000 companies. Over the past 12 years, we have delivered multiple projects for clients from various industries like FMCG, Restaurants, Banking and Finance, Automobiles, Ecommerce, Television and Broadcast Agencies. Big Rattle Technologies Private Limited is ISO27001 Certified\n",
    "\n",
    "You will get:\n",
    "\n",
    "End-to-end exposure in software design and development of products, web applications and mobile applications.\n",
    "Opportunities to participate in the decision-making process and take leadership roles.\n",
    "Opportunities to build and render exceptional products and services.\n",
    "Employee Benefits include:\n",
    "\n",
    "Healthcare coverage\n",
    "Certification reimbursement\n",
    "5-day hybrid work week\n",
    "Laptop\n",
    "Social media presence:\n",
    "\n",
    "Website: www.bigrattle.com\n",
    "Glassdoor: https://www.glassdoor.co.in/Reviews/Big-Rattle-Technologies-Reviews-E597660.htm\n",
    "LinkedIn: https://www.linkedin.com/company/big-rattle-technologies\n",
    "Facebook: https://www.facebook.com/bigrattle\n",
    "Consistent Clutch leader for 3 consecutive years 2021 | 2020 | 2019.\n",
    "Featured on Mobile App Daily among the Top 10 App development companies in Mumbai.\n",
    "Featured by The Manifest among the Top 30 IT Services Company in Mumbai and listed at #7 in the Top 20 BI App Developers in Mumbai.\n",
    "Leading the list on Cision PRWeb's Top Software Development Companies of 2020.\n",
    "Ranked at #4 by Visual Objects on Top IT Consulting Firms in Mumbai\n",
    "Recognized by Great Managers' Forbes India.\n",
    "\"\"\",return_tensors=\"pt\").input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Big Rattle Technologies'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
    "tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
